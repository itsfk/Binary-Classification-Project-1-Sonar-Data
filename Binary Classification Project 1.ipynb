{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1QZxXckQ0wZb"
   },
   "source": [
    "#  Baseline Neural Network Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_eBu_LC90wZg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ar0d1BVW0wZ5"
   },
   "source": [
    "# Next, we can initialize the random number generator to ensure that we always get the same results when executing this code. This will help if we are debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "w5XVf2I50wZ9"
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKt9vHvU0waI"
   },
   "source": [
    "# Load the dataset and split the columns into 60 input variables (X) and 1 output variable (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23867,
     "status": "ok",
     "timestamp": 1528821250472,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "yIru_ape0waM",
    "outputId": "e97ecea3-1f87-4843-be9c-2b5a29acd495"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-5f02c24f-9ed4-45c3-9fa8-dd8e63bc8bde\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-5f02c24f-9ed4-45c3-9fa8-dd8e63bc8bde\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving sonar.csv to sonar (1).csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "df=pd.read_csv(\"sonar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1065,
     "status": "ok",
     "timestamp": 1528821251643,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "enHGsoGD0waX",
    "outputId": "2976adad-3f5c-4f82-e7d6-a732f1edcb24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "0  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "1  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "2  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "3  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "4  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "\n",
       "   0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090  \\\n",
       "0  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "1  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "2  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "3  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "4  0.3039 ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027  0.0051   \n",
       "\n",
       "   0.0032  R  \n",
       "0  0.0044  R  \n",
       "1  0.0078  R  \n",
       "2  0.0117  R  \n",
       "3  0.0094  R  \n",
       "4  0.0062  R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1163
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 917,
     "status": "ok",
     "timestamp": 1528821252801,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "iWOphujj0wal",
    "outputId": "f25c10c0-f029-4554-8767-565b53e0de4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 207 entries, 0 to 206\n",
      "Data columns (total 61 columns):\n",
      "0.0200    207 non-null float64\n",
      "0.0371    207 non-null float64\n",
      "0.0428    207 non-null float64\n",
      "0.0207    207 non-null float64\n",
      "0.0954    207 non-null float64\n",
      "0.0986    207 non-null float64\n",
      "0.1539    207 non-null float64\n",
      "0.1601    207 non-null float64\n",
      "0.3109    207 non-null float64\n",
      "0.2111    207 non-null float64\n",
      "0.1609    207 non-null float64\n",
      "0.1582    207 non-null float64\n",
      "0.2238    207 non-null float64\n",
      "0.0645    207 non-null float64\n",
      "0.0660    207 non-null float64\n",
      "0.2273    207 non-null float64\n",
      "0.3100    207 non-null float64\n",
      "0.2999    207 non-null float64\n",
      "0.5078    207 non-null float64\n",
      "0.4797    207 non-null float64\n",
      "0.5783    207 non-null float64\n",
      "0.5071    207 non-null float64\n",
      "0.4328    207 non-null float64\n",
      "0.5550    207 non-null float64\n",
      "0.6711    207 non-null float64\n",
      "0.6415    207 non-null float64\n",
      "0.7104    207 non-null float64\n",
      "0.8080    207 non-null float64\n",
      "0.6791    207 non-null float64\n",
      "0.3857    207 non-null float64\n",
      "0.1307    207 non-null float64\n",
      "0.2604    207 non-null float64\n",
      "0.5121    207 non-null float64\n",
      "0.7547    207 non-null float64\n",
      "0.8537    207 non-null float64\n",
      "0.8507    207 non-null float64\n",
      "0.6692    207 non-null float64\n",
      "0.6097    207 non-null float64\n",
      "0.4943    207 non-null float64\n",
      "0.2744    207 non-null float64\n",
      "0.0510    207 non-null float64\n",
      "0.2834    207 non-null float64\n",
      "0.2825    207 non-null float64\n",
      "0.4256    207 non-null float64\n",
      "0.2641    207 non-null float64\n",
      "0.1386    207 non-null float64\n",
      "0.1051    207 non-null float64\n",
      "0.1343    207 non-null float64\n",
      "0.0383    207 non-null float64\n",
      "0.0324    207 non-null float64\n",
      "0.0232    207 non-null float64\n",
      "0.0027    207 non-null float64\n",
      "0.0065    207 non-null float64\n",
      "0.0159    207 non-null float64\n",
      "0.0072    207 non-null float64\n",
      "0.0167    207 non-null float64\n",
      "0.0180    207 non-null float64\n",
      "0.0084    207 non-null float64\n",
      "0.0090    207 non-null float64\n",
      "0.0032    207 non-null float64\n",
      "R         207 non-null object\n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 98.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1528821254114,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "-03RGzFQ0wa3",
    "outputId": "6a0b30b9-2c79-4d54-8a85-2c0397c56d6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0232</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029208</td>\n",
       "      <td>0.038443</td>\n",
       "      <td>0.043837</td>\n",
       "      <td>0.054053</td>\n",
       "      <td>0.075105</td>\n",
       "      <td>0.104599</td>\n",
       "      <td>0.121591</td>\n",
       "      <td>0.134677</td>\n",
       "      <td>0.177361</td>\n",
       "      <td>0.208245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016034</td>\n",
       "      <td>0.013472</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.010917</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.006523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023038</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>0.046583</td>\n",
       "      <td>0.055669</td>\n",
       "      <td>0.059247</td>\n",
       "      <td>0.061897</td>\n",
       "      <td>0.085340</td>\n",
       "      <td>0.118311</td>\n",
       "      <td>0.134741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.005038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.024450</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.066950</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.080350</td>\n",
       "      <td>0.096750</td>\n",
       "      <td>0.111150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>0.152200</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.101050</td>\n",
       "      <td>0.134150</td>\n",
       "      <td>0.153050</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.016750</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.008550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0.0200      0.0371      0.0428      0.0207      0.0954      0.0986  \\\n",
       "count  207.000000  207.000000  207.000000  207.000000  207.000000  207.000000   \n",
       "mean     0.029208    0.038443    0.043837    0.054053    0.075105    0.104599   \n",
       "std      0.023038    0.033040    0.038521    0.046583    0.055669    0.059247   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013300    0.016400    0.018900    0.024450    0.037700    0.066950   \n",
       "50%      0.022800    0.030800    0.034200    0.044100    0.062000    0.092100   \n",
       "75%      0.035800    0.048100    0.058200    0.065700    0.101050    0.134150   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "           0.1539      0.1601      0.3109      0.2111     ...          0.0232  \\\n",
       "count  207.000000  207.000000  207.000000  207.000000     ...      207.000000   \n",
       "mean     0.121591    0.134677    0.177361    0.208245     ...        0.016034   \n",
       "std      0.061897    0.085340    0.118311    0.134741     ...        0.012027   \n",
       "min      0.003300    0.005500    0.007500    0.011300     ...        0.000000   \n",
       "25%      0.080600    0.080350    0.096750    0.111150     ...        0.008350   \n",
       "50%      0.105600    0.111900    0.152200    0.181000     ...        0.013800   \n",
       "75%      0.153050    0.169800    0.231500    0.269000     ...        0.020700   \n",
       "max      0.372900    0.459000    0.682800    0.710600     ...        0.100400   \n",
       "\n",
       "           0.0027      0.0065      0.0159      0.0072      0.0167      0.0180  \\\n",
       "count  207.000000  207.000000  207.000000  207.000000  207.000000  207.000000   \n",
       "mean     0.013472    0.010729    0.010917    0.009300    0.008181    0.007771   \n",
       "std      0.009628    0.007071    0.007310    0.007103    0.005719    0.005756   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007350    0.005050    0.005350    0.004100    0.004400    0.003700   \n",
       "50%      0.011500    0.009600    0.009300    0.007500    0.006800    0.005900   \n",
       "75%      0.016750    0.014900    0.014450    0.012100    0.010350    0.010350   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "           0.0084      0.0090      0.0032  \n",
       "count  207.000000  207.000000  207.000000  \n",
       "mean     0.007947    0.007936    0.006523  \n",
       "std      0.006485    0.006196    0.005038  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003650    0.003100  \n",
       "50%      0.005800    0.006300    0.005300  \n",
       "75%      0.010400    0.010350    0.008550  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_H472qQz0wbF"
   },
   "outputs": [],
   "source": [
    "data=df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "91vOYbNv0wbS"
   },
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X = data[:,0:60].astype(float)\n",
    "Y = data[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1761,
     "status": "ok",
     "timestamp": 1528821259256,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "oV1fOwaq0wbm",
    "outputId": "b5830559-f188-4a5a-f68e-f136c939e0f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0453, 0.0523, 0.0843, ..., 0.0049, 0.0052, 0.0044],\n",
       "       [0.0262, 0.0582, 0.1099, ..., 0.0164, 0.0095, 0.0078],\n",
       "       [0.01  , 0.0171, 0.0623, ..., 0.0044, 0.004 , 0.0117],\n",
       "       ...,\n",
       "       [0.0522, 0.0437, 0.018 , ..., 0.0138, 0.0077, 0.0031],\n",
       "       [0.0303, 0.0353, 0.049 , ..., 0.0079, 0.0036, 0.0048],\n",
       "       [0.026 , 0.0363, 0.0136, ..., 0.0036, 0.0061, 0.0115]])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1528821260439,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "0i8DIUOc0wb1",
    "outputId": "b6c7f95c-9c4c-4bc3-b881-a5e1a396b629"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qzo7HLS00wcF"
   },
   "source": [
    "# The output variable is string values. We must convert them into integer values 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wxhfvDgc0wcJ"
   },
   "outputs": [],
   "source": [
    "labelEncode = LabelEncoder()\n",
    "Y =  labelEncode.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 894,
     "status": "ok",
     "timestamp": 1528821262920,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "8PCdkS5q0wcW",
    "outputId": "86eea761-6e96-4bfc-ed6d-af14122b92b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pon5y-m60wch"
   },
   "source": [
    "# Creating a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8bAo4er80wck"
   },
   "outputs": [],
   "source": [
    "#Initializations define the way to set the initial random weights of Keras layers\n",
    "from keras import initializers\n",
    "initial = initializers.random_normal()\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, kernel_initializer=initial, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=initial, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yi5CPSIR0wcz"
   },
   "source": [
    "### Now it is time to evaluate this model using stratified cross validation in the scikit-learn framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58083,
     "status": "ok",
     "timestamp": 1528821322717,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "6JhrMIHE0wdJ",
    "outputId": "9eaf8362-3417-4fcc-8bb9-e21e99233aab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 82.09% (7.59%)\n"
     ]
    }
   ],
   "source": [
    "#To use Keras models with scikit-learn, we must use the KerasClassifier wrapper.\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "kFolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kFolds)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJgsjoT60wdj"
   },
   "source": [
    "# Re-Run The Baseline Model With Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 65048,
     "status": "ok",
     "timestamp": 1528821387881,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "MEIML16Q0wdo",
    "outputId": "204a0934-f52b-417d-db44-42c3fcc454b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 86.02% (3.24%)\n"
     ]
    }
   ],
   "source": [
    "# Standardization is important because the data is rescaled such that the mean value for each attribute is 0 and the standard deviation is 1. \n",
    "# evaluate baseline model with standardized dataset\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kFolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kFolds)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPZOuX-c0wd-"
   },
   "source": [
    "# Tuning Layers and Number of Neurons in The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BI3psMan0weC"
   },
   "source": [
    "### 4.1. Evaluate a Smaller Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 71168,
     "status": "ok",
     "timestamp": 1528821459161,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "FtVUrrT70weI",
    "outputId": "2168b635-470d-4911-ce03-7143e38b42c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 85.50% (3.70%)\n"
     ]
    }
   ],
   "source": [
    "def create_smaller():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kFolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X,Y, cv=kFolds)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xeTUfWS0weo"
   },
   "source": [
    "# Step 4.2. Evaluate a Larger Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 85414,
     "status": "ok",
     "timestamp": 1528821544682,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "64JiAzls0weu",
    "outputId": "05033c6c-5da8-47af-e354-89ddff53d490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 87.45% (4.88%)\n"
     ]
    }
   ],
   "source": [
    "def create_larger():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kFolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kFolds)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjeHvDC30wfJ"
   },
   "source": [
    "# Rewriting the code using the Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17552,
     "status": "ok",
     "timestamp": 1528821562346,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "pfjzF7RS0wfM",
    "outputId": "f7f4d5a1-efbc-4526-c0c5-d868c8f61dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 87.42% (4.02%)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "def kerasApiModel():\n",
    "    # create model\n",
    "                    inputs = keras.Input(shape=(60,))\n",
    "                    a = layers.Dense(60, activation='relu')(inputs)\n",
    "                    a = layers.Dense(10, activation='relu')(a)\n",
    "                    outputs = layers.Dense(1, activation='sigmoid')(a)\n",
    "                    model = keras.Model(inputs, outputs)\n",
    "                     # Compile model\n",
    "                    model.compile(loss='binary_crossentropy', optimizer='adam',   metrics=['accuracy'])\n",
    "                    return model\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=kerasApiModel, epochs=20, batch_size=4, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kFolds = StratifiedKFold(n_splits=4, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kFolds)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlleLLvs0wff"
   },
   "source": [
    "# Rewriting the code by doing Model Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4260,
     "status": "ok",
     "timestamp": 1528821566742,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "IANpKnf30wfh",
    "outputId": "f86db55c-e75d-48f6-a0e1-876db8add873"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f8e5100ef60>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "        def __init__(self):\n",
    "            \n",
    "                        super(MyModel, self).__init__()\n",
    "                        self.dense1 = Dense(60, activation=\"relu\")\n",
    "                        self.dense2 = Dense(10, activation='relu')\n",
    "                        self.dense3 = Dense(1, activation='sigmoid')\n",
    "\n",
    "        def call(self, inputs):\n",
    "\n",
    "                        x = self.dense1(inputs)\n",
    "                        x = self.dense2(x)\n",
    "                        return self.dense3(x)\n",
    "                        \n",
    "                    \n",
    "model = MyModel()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',   metrics=['accuracy'])\n",
    "model.fit(X,Y, epochs=20, batch_size=4,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3528
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14626,
     "status": "ok",
     "timestamp": 1528822199573,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "f8yHXwbU48T5",
    "outputId": "97ab9930-ea97-4dbd-8dec-4db864112bde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.6807 - acc: 0.5652\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 489us/step - loss: 0.6301 - acc: 0.6812\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 477us/step - loss: 0.5984 - acc: 0.7005\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 511us/step - loss: 0.5555 - acc: 0.7246\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 495us/step - loss: 0.5116 - acc: 0.7391\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 474us/step - loss: 0.4989 - acc: 0.7440\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 480us/step - loss: 0.4497 - acc: 0.8116\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 546us/step - loss: 0.4299 - acc: 0.8019\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 495us/step - loss: 0.4163 - acc: 0.8309\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 499us/step - loss: 0.4133 - acc: 0.8164\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 460us/step - loss: 0.4095 - acc: 0.8164\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 496us/step - loss: 0.3805 - acc: 0.8309\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 495us/step - loss: 0.3544 - acc: 0.8502\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 603us/step - loss: 0.3434 - acc: 0.8551\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 0s 615us/step - loss: 0.3367 - acc: 0.8696\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 0s 508us/step - loss: 0.3191 - acc: 0.8792\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 0s 505us/step - loss: 0.3145 - acc: 0.8937\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 0s 481us/step - loss: 0.2983 - acc: 0.8696\n",
      "Epoch 19/100\n",
      "207/207 [==============================] - 0s 546us/step - loss: 0.2892 - acc: 0.8937\n",
      "Epoch 20/100\n",
      "207/207 [==============================] - 0s 502us/step - loss: 0.2847 - acc: 0.9082\n",
      "Epoch 21/100\n",
      "207/207 [==============================] - 0s 462us/step - loss: 0.2834 - acc: 0.8696\n",
      "Epoch 22/100\n",
      "207/207 [==============================] - 0s 477us/step - loss: 0.2560 - acc: 0.9082\n",
      "Epoch 23/100\n",
      "207/207 [==============================] - 0s 586us/step - loss: 0.2564 - acc: 0.9034\n",
      "Epoch 24/100\n",
      "207/207 [==============================] - 0s 496us/step - loss: 0.2391 - acc: 0.8986\n",
      "Epoch 25/100\n",
      "207/207 [==============================] - 0s 472us/step - loss: 0.2515 - acc: 0.8937\n",
      "Epoch 26/100\n",
      "207/207 [==============================] - 0s 507us/step - loss: 0.2175 - acc: 0.9179\n",
      "Epoch 27/100\n",
      "207/207 [==============================] - 0s 501us/step - loss: 0.2155 - acc: 0.8986\n",
      "Epoch 28/100\n",
      "207/207 [==============================] - 0s 562us/step - loss: 0.2072 - acc: 0.9082\n",
      "Epoch 29/100\n",
      "207/207 [==============================] - 0s 496us/step - loss: 0.2394 - acc: 0.9034\n",
      "Epoch 30/100\n",
      "207/207 [==============================] - 0s 463us/step - loss: 0.1916 - acc: 0.9324\n",
      "Epoch 31/100\n",
      "207/207 [==============================] - 0s 563us/step - loss: 0.1729 - acc: 0.9469\n",
      "Epoch 32/100\n",
      "207/207 [==============================] - 0s 511us/step - loss: 0.1657 - acc: 0.9179\n",
      "Epoch 33/100\n",
      "207/207 [==============================] - 0s 500us/step - loss: 0.1607 - acc: 0.9469\n",
      "Epoch 34/100\n",
      "207/207 [==============================] - 0s 615us/step - loss: 0.1568 - acc: 0.9517\n",
      "Epoch 35/100\n",
      "207/207 [==============================] - 0s 509us/step - loss: 0.1685 - acc: 0.9324\n",
      "Epoch 36/100\n",
      "207/207 [==============================] - 0s 461us/step - loss: 0.1375 - acc: 0.9614\n",
      "Epoch 37/100\n",
      "207/207 [==============================] - 0s 468us/step - loss: 0.1258 - acc: 0.9614\n",
      "Epoch 38/100\n",
      "207/207 [==============================] - 0s 501us/step - loss: 0.1336 - acc: 0.9662\n",
      "Epoch 39/100\n",
      "207/207 [==============================] - 0s 474us/step - loss: 0.1081 - acc: 0.9807\n",
      "Epoch 40/100\n",
      "207/207 [==============================] - 0s 484us/step - loss: 0.1159 - acc: 0.9807\n",
      "Epoch 41/100\n",
      "207/207 [==============================] - 0s 512us/step - loss: 0.1247 - acc: 0.9662\n",
      "Epoch 42/100\n",
      "207/207 [==============================] - 0s 568us/step - loss: 0.0958 - acc: 0.9662\n",
      "Epoch 43/100\n",
      "207/207 [==============================] - 0s 512us/step - loss: 0.1024 - acc: 0.9662\n",
      "Epoch 44/100\n",
      "207/207 [==============================] - 0s 491us/step - loss: 0.1108 - acc: 0.9662\n",
      "Epoch 45/100\n",
      "207/207 [==============================] - 0s 476us/step - loss: 0.0947 - acc: 0.9807\n",
      "Epoch 46/100\n",
      "207/207 [==============================] - 0s 487us/step - loss: 0.0918 - acc: 0.9855\n",
      "Epoch 47/100\n",
      "207/207 [==============================] - 0s 526us/step - loss: 0.0699 - acc: 0.9903\n",
      "Epoch 48/100\n",
      "207/207 [==============================] - 0s 445us/step - loss: 0.0629 - acc: 0.9855\n",
      "Epoch 49/100\n",
      "115/207 [===============>..............] - ETA: 0s - loss: 0.0651 - acc: 0.9826    207/207 [==============================] - 0s 584us/step - loss: 0.0677 - acc: 0.9807\n",
      "Epoch 50/100\n",
      "207/207 [==============================] - 0s 591us/step - loss: 0.0583 - acc: 0.9855\n",
      "Epoch 51/100\n",
      "207/207 [==============================] - 0s 492us/step - loss: 0.0587 - acc: 0.9952\n",
      "Epoch 52/100\n",
      "207/207 [==============================] - 0s 483us/step - loss: 0.0602 - acc: 0.9903\n",
      "Epoch 53/100\n",
      "207/207 [==============================] - 0s 458us/step - loss: 0.0488 - acc: 0.9903\n",
      "Epoch 54/100\n",
      "207/207 [==============================] - 0s 628us/step - loss: 0.0454 - acc: 0.9903\n",
      "Epoch 55/100\n",
      "207/207 [==============================] - 0s 476us/step - loss: 0.0878 - acc: 0.9565\n",
      "Epoch 56/100\n",
      "207/207 [==============================] - 0s 499us/step - loss: 0.0685 - acc: 0.9807\n",
      "Epoch 57/100\n",
      "207/207 [==============================] - 0s 498us/step - loss: 0.0396 - acc: 0.9952\n",
      "Epoch 58/100\n",
      "207/207 [==============================] - 0s 479us/step - loss: 0.0438 - acc: 0.9903\n",
      "Epoch 59/100\n",
      "207/207 [==============================] - 0s 486us/step - loss: 0.0395 - acc: 0.9903\n",
      "Epoch 60/100\n",
      "207/207 [==============================] - 0s 498us/step - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "207/207 [==============================] - 0s 545us/step - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "207/207 [==============================] - 0s 500us/step - loss: 0.0271 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "207/207 [==============================] - 0s 488us/step - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "207/207 [==============================] - 0s 471us/step - loss: 0.0231 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "207/207 [==============================] - 0s 592us/step - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "207/207 [==============================] - 0s 516us/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "207/207 [==============================] - 0s 490us/step - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "207/207 [==============================] - 0s 633us/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "207/207 [==============================] - 0s 578us/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "207/207 [==============================] - 0s 613us/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "207/207 [==============================] - 0s 500us/step - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "  5/207 [..............................] - ETA: 0s - loss: 0.0087 - acc: 1.0000207/207 [==============================] - 0s 557us/step - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "207/207 [==============================] - 0s 478us/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "207/207 [==============================] - 0s 468us/step - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "207/207 [==============================] - 0s 458us/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "207/207 [==============================] - 0s 493us/step - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "207/207 [==============================] - 0s 455us/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "207/207 [==============================] - 0s 508us/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "207/207 [==============================] - 0s 473us/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "207/207 [==============================] - 0s 468us/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "207/207 [==============================] - 0s 493us/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "207/207 [==============================] - 0s 452us/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "207/207 [==============================] - 0s 464us/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "207/207 [==============================] - 0s 508us/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "207/207 [==============================] - 0s 492us/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "207/207 [==============================] - 0s 460us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "207/207 [==============================] - 0s 470us/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "207/207 [==============================] - 0s 493us/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "207/207 [==============================] - 0s 437us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "207/207 [==============================] - 0s 525us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "207/207 [==============================] - 0s 501us/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "207/207 [==============================] - 0s 443us/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "207/207 [==============================] - 0s 530us/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "207/207 [==============================] - 0s 467us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/207 [..............................] - ETA: 0s - loss: 0.0019 - acc: 1.0000207/207 [==============================] - 0s 422us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "207/207 [==============================] - 0s 512us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "207/207 [==============================] - 0s 493us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "207/207 [==============================] - 0s 456us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "207/207 [==============================] - 0s 458us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "207/207 [==============================] - 0s 484us/step - loss: 0.0035 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e50ca0748>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# **Build Model from scratch without Scikit Learn**\n",
    "from keras import optimizers\n",
    "def final_model():\n",
    "  network = Sequential()\n",
    "  network.add(Dense(60, activation='relu',input_shape=(60,)))\n",
    "  network.add(Dense(30, activation='relu'))\n",
    "  network.add(Dense(1, activation='sigmoid'))\n",
    "  network.compile(optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "  return network\n",
    "\n",
    "model = final_model()\n",
    "model.fit(X, Y , epochs=100, batch_size=5 , verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aQ8Ycj045MOy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Binary Classification.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
